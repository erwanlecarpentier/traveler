/**
 * @brief Simulation parameters
 */
simulation_limit_time = 1000
nb_simulations = 10
backup_path = "data/backup.csv"

/**
 * @brief Environment parameters
 *
 * Generate map:
 * true: generate a random map
 * false: use the graph duration matrix to generate the map
 */
reward_scaling_max = 80.0 ///< Duration after which the reward is -1.0
goal_reward = 1.0
dead_end_reward = -1.0
noop_reward = 0.0

generate_map = false

/**
 * Parameters for auto-generated map
 *
 * Sampler selector:
 * 0: 1st order random uniform
 * 1: 2nd order random uniform
 * 2: 2nd order epsilon-random uniform
 * 3: cos heuristic
 */
sampler_selector = 3
symmetric_graph = true ///< Set to true if each edge should have its symmetric
nb_time_steps = 1000
time_steps_width = 10
nb_nodes = 1000
min_nb_edges_per_node = 3
duration_min = 0.0
duration_max = 30.0
lip = 1.0 // Lipschitz constant ie maximum duration variation between subsequent time steps
save_duration_matrix = true
output_duration_matrix = "config/generated_map.csv"

/** Parameters for loaded duration matrix */
input_duration_matrix = "config/backup/cos_heuristic_maps/map9.csv"
initial_location = "n0"
terminal_location = "n1"
csv_sep = ";"

/**
 * @brief Policy parameters
 *
 * Policy selector:
 * 0: random
 * 1: MCTS
 * 2: UCT
 * 3: TMP_MCTS
 * 4: TMP_UCT
 */
policy_selector = 2
is_model_dynamic = false
discount_factor = 1.0
uct_parameter = 0.7
tree_search_budget = 100000
default_policy_horizon = 100

regression_regularization = 0.
polynomial_regression_degree = 1

